{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration/Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"../data/imdb_data.csv\"\n",
    "data = pd.read_csv(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('<br /><br />','')\n",
    "    text = text.lower() \n",
    "    text = text.strip()  \n",
    "    text = re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"review_clean\"] = data[\"review\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    text = ' '.join([i for i in text.split() if i not in stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = list(set(stopwords.words(\"english\")))\n",
    "data[\"review_clean\"] = data[\"review\"].apply(lambda x: remove_stopwords(x, stopwords_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatizer(text, lemmatizer):\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "data[\"review_clean\"] = data[\"review\"].apply(lambda x: apply_lemmatizer(x, lemmatizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"review_clean\"]\n",
    "y = data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46047</th>\n",
       "      <td>Upon seeing this film once again it appeared i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15587</th>\n",
       "      <td>As a popular sport, surfing was liked by many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>For a really wonderful movie, you could also t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32117</th>\n",
       "      <td>Being a huge die-hard Monkey Island fan, I fug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31251</th>\n",
       "      <td>This film is bad. Not so bad it is good. Just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21052</th>\n",
       "      <td>Though, short lived \"The Amazing Spider-Man\" w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22022</th>\n",
       "      <td>(Spoilers) \"Cash Crop\" goes something like thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27575</th>\n",
       "      <td>Watching this on Comcast On-Demand.&lt;br /&gt;&lt;br /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>This was surely the stupidest, crudest, most r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15127</th>\n",
       "      <td>I really like slasher movies,but this one is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46201</th>\n",
       "      <td>I gave this movie a four-star rating for a few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;However, the ladies of all ages wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34804</th>\n",
       "      <td>It seems no matter what I see her in, Christin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18513</th>\n",
       "      <td>For those of us who are part of the real world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19211</th>\n",
       "      <td>In my opinion, A GUY THING is a hilarious, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39730</th>\n",
       "      <td>Too many secondary plot lines without a primar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42492</th>\n",
       "      <td>Freeway Killer, Is a Madman who shoots people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45005</th>\n",
       "      <td>I read all the reviews here AFTER watching thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41797</th>\n",
       "      <td>How better to describe it than scuzzy criminal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>i think it is great one of my favourite films ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21742</th>\n",
       "      <td>Ever wanted to eat worms? Here's a 'documentar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34115</th>\n",
       "      <td>This is one of the best movies to come from Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>*Spoilers and extreme bashing lay ahead*&lt;br /&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19467</th>\n",
       "      <td>Christopher Nolan's first film is a 'no budget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10729</th>\n",
       "      <td>Did Beavis and Butthead make this movie? It is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25584</th>\n",
       "      <td>Oscar-caliber performance by Peter Falk in an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27217</th>\n",
       "      <td>This outstanding Argentine independent film is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35317</th>\n",
       "      <td>Don't get me wrong. I've got a considerable so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45261</th>\n",
       "      <td>this is a great movie. I love the series on tv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43279</th>\n",
       "      <td>I have always been keen on watching Hong Kong ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "46047  Upon seeing this film once again it appeared i...\n",
       "15587  As a popular sport, surfing was liked by many ...\n",
       "1883   For a really wonderful movie, you could also t...\n",
       "32117  Being a huge die-hard Monkey Island fan, I fug...\n",
       "31251  This film is bad. Not so bad it is good. Just ...\n",
       "21052  Though, short lived \"The Amazing Spider-Man\" w...\n",
       "22022  (Spoilers) \"Cash Crop\" goes something like thi...\n",
       "27575  Watching this on Comcast On-Demand.<br /><br /...\n",
       "4148   This was surely the stupidest, crudest, most r...\n",
       "15127  I really like slasher movies,but this one is t...\n",
       "46201  I gave this movie a four-star rating for a few...\n",
       "1906   <br /><br />However, the ladies of all ages wi...\n",
       "34804  It seems no matter what I see her in, Christin...\n",
       "18513  For those of us who are part of the real world...\n",
       "19211  In my opinion, A GUY THING is a hilarious, wit...\n",
       "39730  Too many secondary plot lines without a primar...\n",
       "42492  Freeway Killer, Is a Madman who shoots people ...\n",
       "45005  I read all the reviews here AFTER watching thi...\n",
       "41797  How better to describe it than scuzzy criminal...\n",
       "948    i think it is great one of my favourite films ...\n",
       "21742  Ever wanted to eat worms? Here's a 'documentar...\n",
       "34115  This is one of the best movies to come from Bo...\n",
       "2918   *Spoilers and extreme bashing lay ahead*<br />...\n",
       "19467  Christopher Nolan's first film is a 'no budget...\n",
       "10729  Did Beavis and Butthead make this movie? It is...\n",
       "25584  Oscar-caliber performance by Peter Falk in an ...\n",
       "27217  This outstanding Argentine independent film is...\n",
       "35317  Don't get me wrong. I've got a considerable so...\n",
       "45261  this is a great movie. I love the series on tv...\n",
       "43279  I have always been keen on watching Hong Kong ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[X_test.index][[\"review\"]].sample(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[X_test.index][[\"review\"]].sample(n=30).to_csv(r\"../data/test_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF on tokens\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, min_df=0.05)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_models/tfidf-vectorizer.sav']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf_vectorizer, \"../saved_models/tfidf-vectorizer.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "train: 0.84288\n",
      "test: 0.83616\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=42)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"train:\", accuracy_score(y_train, lr.predict(X_train_tfidf)))\n",
    "print(\"test:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_models/logistic_regression.sav']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, \"../saved_models/logistic_regression.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests with other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB:\n",
      "train: 0.81584\n",
      "test: 0.81248\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = mnb.predict(X_test_tfidf)\n",
    "print(\"Multinomial NB:\")\n",
    "print(\"train:\", accuracy_score(y_train, mnb.predict(X_train_tfidf)))\n",
    "print(\"test:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "train: 0.8598133333333333\n",
      "test: 0.78712\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "forest = RandomForestClassifier(max_depth=12, n_estimators=200, min_samples_split=4, criterion=\"entropy\", random_state=0)\n",
    "forest.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = forest.predict(X_test_tfidf)\n",
    "print(\"Random Forest:\")\n",
    "print(\"train:\", accuracy_score(y_train, forest.predict(X_train_tfidf)))\n",
    "print(\"test:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
