{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration/Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"../data/imdb_data.csv\"\n",
    "data = pd.read_csv(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('<br /><br />','')\n",
    "    text = text.lower() \n",
    "    text = text.strip()  \n",
    "    text = re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"review_clean\"] = data[\"review\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    text = ' '.join([i for i in text.split() if i not in stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = list(set(stopwords.words(\"english\")))\n",
    "data[\"review_clean\"] = data[\"review\"].apply(lambda x: remove_stopwords(x, stopwords_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lemmatizer(text, lemmatizer):\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "data[\"review_clean\"] = data[\"review\"].apply(lambda x: apply_lemmatizer(x, lemmatizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"review_clean\"]\n",
    "y = data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18627</th>\n",
       "      <td>As a fan of Notorious B.I.G., I was looking fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18084</th>\n",
       "      <td>Deep Water (2006) ****&lt;br /&gt;&lt;br /&gt;\"It is indif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Turn your backs away or you're gonna get in bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38062</th>\n",
       "      <td>This is a great ending to the show. The fact t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48607</th>\n",
       "      <td>Yes, bad acting isn't only one thing to mentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43104</th>\n",
       "      <td>This was one of the most dishonest, meaningles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38567</th>\n",
       "      <td>Seeing that this got a theatrical release nowh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16978</th>\n",
       "      <td>The primary aspect of this film which most peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47293</th>\n",
       "      <td>I've had this movie on tape for years and star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40253</th>\n",
       "      <td>When I think about TV movies, I always think o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31854</th>\n",
       "      <td>The movie is steeped in religion, so it is imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49082</th>\n",
       "      <td>I went out of my way to get this film, and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>A typical old b&amp;w film. The dialogues are some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>Recap: The morning after his bachelor party Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36134</th>\n",
       "      <td>I'm hearing rumors of an upcoming \"Leonard Nim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30072</th>\n",
       "      <td>I really wanted to see this film - I thought t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105</th>\n",
       "      <td>As an amateur historian of WW2/Nazi Germany, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>For a long time, this was my favorite of the B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36874</th>\n",
       "      <td>While the dog was cute, the film was not. It w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>Above-average film and acting partly spoiled b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19795</th>\n",
       "      <td>*****Spoiler or two, not that is matters******...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>Stanwyck at her villainous best, Robinson her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43399</th>\n",
       "      <td>\"Subconscious Cruelty\" has to be one of the mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17900</th>\n",
       "      <td>One of the most excellent movies ever produced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29031</th>\n",
       "      <td>I found The FBI Story considerably entertainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>Hear are some of the interesting things our co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37881</th>\n",
       "      <td>Sometimes the Academy doesn't recognize the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>holy Sh*t this was god awful. i sat in the the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>This gem for gore lovers is extremely underrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22976</th>\n",
       "      <td>The back of my DVD describes the plot of \"El C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review\n",
       "18627  As a fan of Notorious B.I.G., I was looking fo...\n",
       "18084  Deep Water (2006) ****<br /><br />\"It is indif...\n",
       "1017   Turn your backs away or you're gonna get in bi...\n",
       "38062  This is a great ending to the show. The fact t...\n",
       "48607  Yes, bad acting isn't only one thing to mentio...\n",
       "43104  This was one of the most dishonest, meaningles...\n",
       "38567  Seeing that this got a theatrical release nowh...\n",
       "16978  The primary aspect of this film which most peo...\n",
       "47293  I've had this movie on tape for years and star...\n",
       "40253  When I think about TV movies, I always think o...\n",
       "31854  The movie is steeped in religion, so it is imp...\n",
       "49082  I went out of my way to get this film, and was...\n",
       "11649  A typical old b&w film. The dialogues are some...\n",
       "5528   Recap: The morning after his bachelor party Pa...\n",
       "36134  I'm hearing rumors of an upcoming \"Leonard Nim...\n",
       "30072  I really wanted to see this film - I thought t...\n",
       "6105   As an amateur historian of WW2/Nazi Germany, I...\n",
       "3994   For a long time, this was my favorite of the B...\n",
       "36874  While the dog was cute, the film was not. It w...\n",
       "6390   Above-average film and acting partly spoiled b...\n",
       "19795  *****Spoiler or two, not that is matters******...\n",
       "2795   Stanwyck at her villainous best, Robinson her ...\n",
       "43399  \"Subconscious Cruelty\" has to be one of the mo...\n",
       "17900  One of the most excellent movies ever produced...\n",
       "29031  I found The FBI Story considerably entertainin...\n",
       "4152   Hear are some of the interesting things our co...\n",
       "37881  Sometimes the Academy doesn't recognize the po...\n",
       "214    holy Sh*t this was god awful. i sat in the the...\n",
       "1346   This gem for gore lovers is extremely underrat...\n",
       "22976  The back of my DVD describes the plot of \"El C..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[X_test.index][[\"review\"]].sample(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[X_test.index][[\"review\"]].sample(n=30).to_csv(r\"../data/test_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF on tokens\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, min_df=0.05)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../artifacts/tfidf-vectorizer.sav']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf_vectorizer, \"../artifacts/tfidf-vectorizer.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "train: 0.8442666666666667\n",
      "test: 0.83272\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=42)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"train:\", accuracy_score(y_train, lr.predict(X_train_tfidf)))\n",
    "print(\"test:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../artifacts/logistic_regression.sav']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, \"../artifacts/logistic_regression.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests with other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB:\n",
      "train: 0.81584\n",
      "test: 0.81248\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = mnb.predict(X_test_tfidf)\n",
    "print(\"Multinomial NB:\")\n",
    "print(\"train:\", accuracy_score(y_train, mnb.predict(X_train_tfidf)))\n",
    "print(\"test:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "train: 0.8598133333333333\n",
      "test: 0.78712\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "forest = RandomForestClassifier(max_depth=12, n_estimators=200, min_samples_split=4, criterion=\"entropy\", random_state=0)\n",
    "forest.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = forest.predict(X_test_tfidf)\n",
    "print(\"Random Forest:\")\n",
    "print(\"train:\", accuracy_score(y_train, forest.predict(X_train_tfidf)))\n",
    "print(\"test:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
